{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "logistics Regression的实现，使用的tf的库，使用的数据是手写识别MNIST数据\n",
    "\n",
    "* Author：xiaoran\n",
    "* Introduction： \n",
    "* Time： 2017-09-05 16:47\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting tmp/data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting tmp/data/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# Import MNIST data\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('tmp/data',one_hot=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# step 0 设置参数，这是tf构建模型的所有套路\n",
    "learning_rate = 0.01\n",
    "training_epochs = 25\n",
    "batch_size = 100\n",
    "display_step = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 loss= 0.050018917\n",
      "Epoch: 0002 loss= 0.049403215\n",
      "Epoch: 0003 loss= 0.022092646\n",
      "Epoch: 0004 loss= 0.045932520\n",
      "Epoch: 0005 loss= 0.047154551\n",
      "Epoch: 0006 loss= 0.056508817\n",
      "Epoch: 0007 loss= 0.054662163\n",
      "Epoch: 0008 loss= 0.050336283\n",
      "Epoch: 0009 loss= 0.057336329\n",
      "Epoch: 0010 loss= 0.021270528\n",
      "Epoch: 0011 loss= 0.026297885\n",
      "Epoch: 0012 loss= 0.053346454\n",
      "Epoch: 0013 loss= 0.021839652\n",
      "Epoch: 0014 loss= 0.052356879\n",
      "Epoch: 0015 loss= 0.040215412\n",
      "Epoch: 0016 loss= 0.051869451\n",
      "Epoch: 0017 loss= 0.046120203\n",
      "Epoch: 0018 loss= 0.038424901\n",
      "Epoch: 0019 loss= 0.040095967\n",
      "Epoch: 0020 loss= 0.095233952\n",
      "Epoch: 0021 loss= 0.020516943\n",
      "Epoch: 0022 loss= 0.053392292\n",
      "Epoch: 0023 loss= 0.064178231\n",
      "Epoch: 0024 loss= 0.040579980\n",
      "Epoch: 0025 loss= 0.077503433\n",
      "Train Finished!\n",
      "Tensor(\"Softmax_4:0\", shape=(?, 10), dtype=float32)\n",
      "Tensor(\"Equal_7:0\", shape=(?,), dtype=bool)\n",
      "Accury: 0.9073\n"
     ]
    }
   ],
   "source": [
    "# 用tf构建模型通用的结构\n",
    "\n",
    "# step 1 定义输出输入占位符\n",
    "# mnist的图片的数据是 28 * 28 = 784,None:表示第一维的数据是任意，这个表示数据的个数\n",
    "# y输出的一个vector有10个元素，分别0-9的类的概率\n",
    "x = tf.placeholder(tf.float32, shape=[None,784]) \n",
    "y = tf.placeholder(tf.float32, shape=[None, 10])\n",
    "\n",
    "\n",
    "# step 2 定义变量，中间使用的变量的格式W和b，我们可以直达 xW + b ---> y \n",
    "# x[None, 784]       W [784, 10]  b[10]     y [None, 10]\n",
    "# 用zero初始化, 在机器学习中，会发生改变的值，定义为变量\n",
    "W = tf.Variable(tf.zeros([784,10]))\n",
    "b = tf.Variable(tf.zeros([10]))\n",
    "\n",
    "\n",
    "# step 3 构建模型\n",
    "pred_y = tf.nn.softmax(tf.matmul(x, W) + b) # 使用的softmax函数\n",
    "\n",
    "\n",
    "# step 4 定义损失函数loss，这里使用的交叉熵（预测值和真实值的交叉熵）的平均值\n",
    "logistic = - tf.reduce_sum(y * tf.log(pred_y))\n",
    "loss = tf.reduce_mean(logistic)\n",
    "\n",
    "\n",
    "# step 4 定义优化器optimizier,很好理解，使用梯度下降的方法，以学习了learning_rate最小化loss\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)\n",
    "\n",
    "\n",
    "# step 5 训练模型\n",
    "with tf.Session() as sess:\n",
    "    # 5.1 初始化所有数据\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    \n",
    "    # 5.2 开始训练\n",
    "    for epoch in range(training_epochs):\n",
    "        mean_loss = 0\n",
    "        # 根据所有的数据和每一次的批处理的数据个数，得到总的批次的数目\n",
    "        total_batch = int(mnist.train.num_examples / batch_size)\n",
    "        for i in range(total_batch):\n",
    "            batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "            \n",
    "            # 参数是optimizer和loss，得到就是两者对应的值\n",
    "            _, per_loss = sess.run([optimizer, loss], feed_dict={x:batch_x, y:batch_y})\n",
    "            \n",
    "            # 计算平均损失loss,\n",
    "            mean_loss = per_loss / total_batch \n",
    "        \n",
    "        # 显示，每个display次进行显示\n",
    "        if (epoch+1) % display_step == 0:\n",
    "            print(\"Epoch:\", '%04d' % (epoch+1), \"loss=\", \"{:.9f}\".format(mean_loss))\n",
    "    \n",
    "    print(\"Train Finished!\")\n",
    "    \n",
    "    print(pred_y)\n",
    "    \n",
    "# step 6 测试model\n",
    "    # tf.argmax(input, axis=None, name=None, dimension=None) 返回tensor中指定维度的最大值的索引（位置）\n",
    "    # tf.cast(x, dtype) 将x转化为dtype的数据类型\n",
    "    # 紧接着这两句是一个模型，计算的在 accuracy.eaval()\n",
    "    correct_prediction = tf.equal(tf.argmax(pred_y ,1), tf.argmax(y ,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "    print('Accury:', accuracy.eval({x:mnist.test.images, y:mnist.test.labels}))\n",
    "\n",
    "# step 7 结束\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 7 False\n"
     ]
    }
   ],
   "source": [
    "# 测试使用tf.argmax函数\n",
    "\n",
    "a = [1,2,6,6,3,4,5,6]\n",
    "b = [1,2,2,5,3,3,5,6]\n",
    "\n",
    "aa = tf.argmax(a)\n",
    "bb = tf.argmax(b)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    a_ = sess.run(aa)\n",
    "    b_ = sess.run(bb)\n",
    "    \n",
    "    c = sess.run(tf.equal(aa,bb))\n",
    "    \n",
    "    print(a_,b_,c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function cast in module tensorflow.python.ops.math_ops:\n",
      "\n",
      "cast(x, dtype, name=None)\n",
      "    Casts a tensor to a new type.\n",
      "    \n",
      "    The operation casts `x` (in case of `Tensor`) or `x.values`\n",
      "    (in case of `SparseTensor`) to `dtype`.\n",
      "    \n",
      "    For example:\n",
      "    \n",
      "    ```python\n",
      "    # tensor `a` is [1.8, 2.2], dtype=tf.float\n",
      "    tf.cast(a, tf.int32) ==> [1, 2]  # dtype=tf.int32\n",
      "    ```\n",
      "    \n",
      "    Args:\n",
      "      x: A `Tensor` or `SparseTensor`.\n",
      "      dtype: The destination type.\n",
      "      name: A name for the operation (optional).\n",
      "    \n",
      "    Returns:\n",
      "      A `Tensor` or `SparseTensor` with same shape as `x`.\n",
      "    \n",
      "    Raises:\n",
      "      TypeError: If `x` cannot be cast to the `dtype`.\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
